{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ee9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voice Extractor\n",
    "import os\n",
    "\n",
    "# First, clone the repository if it doesn't exist\n",
    "if not os.path.exists('Voice_Extractor'):\n",
    "    !git clone -q https://github.com/ReisCook/Voice_Extractor.git\n",
    "    print(\"Repository cloned successfully\")\n",
    "else:\n",
    "    print(\"Repository already exists, skipping clone\")\n",
    "\n",
    "# --- guarantee fixed versions for key dependencies ---\n",
    "!pip uninstall -y -q datasets fsspec numpy  # Add numpy to the uninstall list\n",
    "\n",
    "# Install NumPy 2.0 first to ensure compatibility with Numba\n",
    "!pip install -q \"numpy<2.0.0\" \n",
    "\n",
    "# Install other general dependencies\n",
    "!pip install -q ipywidgets pandas matplotlib huggingface_hub # 'datasets' removed from here\n",
    "\n",
    "# Install requirements from the repo (which might include its own datasets/fsspec, but we'll override next)\n",
    "!pip install -q -r Voice_Extractor/requirements.txt\n",
    "\n",
    "# Force install the known good versions LAST\n",
    "!pip install -q --force-reinstall \"datasets==2.16.1\" \"fsspec==2023.9.2\" \"numpy<2.0.0\"\n",
    "# IMPORTANT: After this cell runs, RESTART THE COLAB RUNTIME (Runtime -> Restart runtime)\n",
    "# ------------------------------------------------\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/content/voice_extractor_cache\"\n",
    "\n",
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from google.colab import files as colab_files\n",
    "from huggingface_hub import login\n",
    "from pathlib import Path\n",
    "\n",
    "# CSS for UI\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "    .widget-label {max-width: none !important; width: auto !important; overflow: visible !important; white-space: normal !important;}\n",
    "    .widget-checkbox > .widget-label {min-width: 250px !important;}\n",
    "    .section-header {font-size: 1.3em; font-weight: bold; color: #1A73E8; margin-top: 20px; \n",
    "                    margin-bottom: 15px; padding-bottom: 5px; border-bottom: 2px solid #1A73E8;}\n",
    "    .warning-box {background-color: #fff3cd; color: #856404; padding: 10px; border: 1px solid #ffeeba; \n",
    "                 border-radius: 5px; margin: 10px 0; font-weight: bold;}\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "# Create UI components\n",
    "def create_section(title):\n",
    "    return widgets.HTML(f\"<div class='section-header'>{title}</div>\")\n",
    "\n",
    "def create_text_input(description, placeholder=\"\", required=False, password=False):\n",
    "    widget_class = widgets.Password if password else widgets.Text\n",
    "    return widget_class(\n",
    "        description=f\"{'*' if required else ''}{description}:\",\n",
    "        placeholder=placeholder,\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_dropdown(description, options, default_value=None):\n",
    "    return widgets.Dropdown(\n",
    "        description=f\"{description}:\",\n",
    "        options=options,\n",
    "        value=default_value or options[0],\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_slider(description, min_val, max_val, step, default):\n",
    "    return widgets.FloatSlider(\n",
    "        description=f\"{description}:\",\n",
    "        min=min_val, max=max_val, step=step, value=default,\n",
    "        layout=widgets.Layout(width='100%')\n",
    "    )\n",
    "\n",
    "def create_checkbox(description, initial_value=False):\n",
    "    return widgets.Checkbox(\n",
    "        description=description,\n",
    "        value=initial_value,\n",
    "        layout=widgets.Layout(width='auto')\n",
    "    )\n",
    "\n",
    "# Create sections\n",
    "auth_section = create_section(\"Authentication & Setup\")\n",
    "input_section = create_section(\"Input Files & Target Name\")\n",
    "processing_section = create_section(\"Basic Processing Options\")\n",
    "performance_section = create_section(\"Performance & Memory Options\")\n",
    "advanced_section = create_section(\"Advanced Settings\")\n",
    "output_section = create_section(\"Output Handling & Export\")\n",
    "\n",
    "# Create warning about memory usage\n",
    "memory_warning = widgets.HTML(\n",
    "    \"<div class='warning-box'>‚ö†Ô∏è 'Skip Demucs' is enabled by default to prevent memory errors in Colab. Disable only if processing small files.</div>\"\n",
    ")\n",
    "\n",
    "# Create inputs\n",
    "hf_token = create_text_input(\"HF Token\", \"hf_...\", required=True, password=True)\n",
    "audio_dir = create_text_input(\"Audio Directory\", \"/content/drive/MyDrive/your_audio_folder\", required=True)\n",
    "reference_file = create_text_input(\"Reference Audio\", \"/content/drive/MyDrive/your_reference.wav\", required=True)\n",
    "target_name = create_text_input(\"Target Name\", \"e.g., JohnDoe\", required=True)\n",
    "output_dir = create_text_input(\"Output Directory\", \"/content/drive/MyDrive/VoiceExtractor_Runs\", required=True)\n",
    "\n",
    "# Processing options\n",
    "output_sr = create_dropdown(\"Output Sample Rate\", [16000, 22050, 24000, 44100, 48000], 24000)\n",
    "whisper_model = create_dropdown(\n",
    "    \"Whisper Model\", \n",
    "    ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3'],\n",
    "    'base.en'\n",
    ")\n",
    "language = create_text_input(\"Language Code\", \"en\")\n",
    "\n",
    "# Performance options - make Skip Demucs enabled by default\n",
    "skip_demucs = create_checkbox(\"Skip Demucs Vocal Separation\", initial_value=True)\n",
    "skip_demucs_description = widgets.HTML(\n",
    "    \"<span style='color:#856404;'>Recommended for Colab. If your audio already has isolated vocals, keep this checked.</span>\"\n",
    ")\n",
    "\n",
    "# Advanced options\n",
    "min_duration = create_slider(\"Min Segment Duration\", 0.5, 10.0, 0.1, 1.0)\n",
    "merge_gap = create_slider(\"Merge Gap\", 0.0, 2.0, 0.05, 0.25)\n",
    "verification_threshold = create_slider(\"Verification Threshold\", 0.0, 1.0, 0.01, 0.69)\n",
    "concat_silence = create_slider(\"Concatenation Silence\", 0.0, 5.0, 0.1, 0.5)\n",
    "disable_speechbrain = create_checkbox(\"Disable SpeechBrain Verification\")\n",
    "skip_rejected_transcripts = create_checkbox(\"Skip Transcribing Rejected Segments\")\n",
    "diar_model = create_dropdown(\n",
    "    \"Diarization Model\", \n",
    "    [\"pyannote/speaker-diarization-3.1\", \"pyannote/speaker-diarization-3.0\"],\n",
    "    \"pyannote/speaker-diarization-3.1\"\n",
    ")\n",
    "osd_model = create_dropdown(\n",
    "    \"OSD Model\", \n",
    "    [\"pyannote/overlapped-speech-detection\", \"pyannote/segmentation-3.0\"],\n",
    "    \"pyannote/overlapped-speech-detection\"\n",
    ")\n",
    "dry_run = create_checkbox(\"Dry Run (Process first 60s only)\")\n",
    "debug_log = create_checkbox(\"Enable Verbose Debug Logging\")\n",
    "keep_temp_files = create_checkbox(\"Keep Temporary Processing Files\")\n",
    "\n",
    "# Output options\n",
    "output_method = create_dropdown(\n",
    "    \"Output Methods\", \n",
    "    [\n",
    "        \"Save ZIP to GDrive & Download to Computer\", \n",
    "        \"Download ZIP to Computer (No GDrive save of .zip)\", \n",
    "        \"Save ZIP to GDrive Only\"\n",
    "    ]\n",
    ")\n",
    "push_to_hf = create_checkbox(\"Push Final Dataset to Hugging Face Hub\")\n",
    "hf_dataset_repo = create_text_input(\"HF Dataset Repo\", \"your_username/dataset_name\")\n",
    "hf_dataset_private = create_checkbox(\"Make HF Dataset Private\", initial_value=True)\n",
    "hf_dataset_repo.disabled = True\n",
    "hf_dataset_private.disabled = True\n",
    "\n",
    "# Status elements\n",
    "status_message = widgets.HTML(\"<div style='margin-top:15px; text-align:center; padding:10px; background:#e0e0e0; border-radius:5px;'>Status: Ready. Configure and click Start.</div>\")\n",
    "validation_message = widgets.HTML()\n",
    "log_output = widgets.Output(layout={'height': '400px', 'overflow_y': 'scroll', 'border': '1px solid #ccc', 'margin-top': '10px'})\n",
    "results_output = widgets.Output(layout={'margin-top': '10px'})\n",
    "\n",
    "# Toggle HF dataset fields\n",
    "def toggle_hf_fields(change):\n",
    "    hf_dataset_repo.disabled = not change['new']\n",
    "    hf_dataset_private.disabled = not change['new']\n",
    "    validate_inputs()\n",
    "\n",
    "push_to_hf.observe(toggle_hf_fields, names='value')\n",
    "\n",
    "# Run button\n",
    "start_btn = widgets.Button(\n",
    "    description=\"üöÄ Start Extraction\",\n",
    "    button_style='success',\n",
    "    icon='play',\n",
    "    disabled=True,\n",
    "    layout={'width': '250px', 'height': '40px', 'margin': '10px 0'}\n",
    ")\n",
    "\n",
    "# Validation function\n",
    "def validate_inputs(*args):\n",
    "    required_fields = [hf_token, audio_dir, reference_file, target_name, output_dir]\n",
    "    all_valid = all(w.value.strip() for w in required_fields)\n",
    "    \n",
    "    if push_to_hf.value:\n",
    "        all_valid = all_valid and hf_dataset_repo.value.strip()\n",
    "    \n",
    "    start_btn.disabled = not all_valid\n",
    "    validation_message.value = \"<span style='color: green;'>All required fields are filled.</span>\" if all_valid else \"<span style='color: red;'>Please fill all required fields marked with *.</span>\"\n",
    "\n",
    "# Add observers\n",
    "for w in [hf_token, audio_dir, reference_file, target_name, output_dir, hf_dataset_repo]:\n",
    "    w.observe(lambda change: validate_inputs(), names='value')\n",
    "\n",
    "# Main function to run extraction\n",
    "def run_extraction(b):\n",
    "    from IPython.display import Audio\n",
    "    # It's good practice to re-import datasets here if its version is critical\n",
    "    # and might be affected by runtime state, though the pip installs should handle it.\n",
    "    import datasets\n",
    "    print(f\"INFO: Using datasets version: {datasets.__version__}\")\n",
    "    import fsspec\n",
    "    print(f\"INFO: Using fsspec version: {fsspec.__version__}\")\n",
    "    import numpy\n",
    "    print(f\"INFO: Using numpy version: {numpy.__version__}\")\n",
    "\n",
    "    log_output.clear_output()\n",
    "    results_output.clear_output()\n",
    "    \n",
    "    start_btn.disabled = True\n",
    "    start_btn.description = \"üîÑ Processing...\"\n",
    "    start_btn.icon = \"spinner\"\n",
    "    status_message.value = \"<div style='margin-top:15px; text-align:center; padding:10px; background:#fff3cd; color:#856404; border:1px solid #ffeeba; border-radius:5px;'>Status: Initializing... Authenticating with Hugging Face...</div>\"\n",
    "    \n",
    "    with log_output:\n",
    "        try:\n",
    "            print(f\"Authenticating with Hugging Face using token starting with: {hf_token.value[:4]}...\")\n",
    "            login(token=hf_token.value, add_to_git_credential=False)\n",
    "            print(\"‚úÖ Authentication successful\")\n",
    "            \n",
    "            audio_dir_path = Path(audio_dir.value)\n",
    "            if not audio_dir_path.exists() or not audio_dir_path.is_dir():\n",
    "                raise FileNotFoundError(f\"Audio directory not found: {audio_dir_path}\")\n",
    "            \n",
    "            audio_files_list = []\n",
    "            for ext in ['.wav', '.mp3', '.m4a', '.flac']:\n",
    "                audio_files_list.extend(list(audio_dir_path.glob(f\"*{ext}\")))\n",
    "            \n",
    "            if not audio_files_list:\n",
    "                raise FileNotFoundError(f\"No audio files found in {audio_dir_path}\")\n",
    "            \n",
    "            input_audio_file = audio_files_list[0]\n",
    "            print(f\"Found audio file: {input_audio_file}\")\n",
    "            \n",
    "            cmd_list = [\n",
    "                \"python\", \"Voice_Extractor/run_extractor.py\",\n",
    "                \"--input-audio\", f'\"{str(input_audio_file)}\"',\n",
    "                \"--reference-audio\", f'\"{str(reference_file.value)}\"',\n",
    "                \"--target-name\", target_name.value,\n",
    "                \"--output-base-dir\", f'\"{str(output_dir.value)}\"',\n",
    "                \"--token\", hf_token.value,\n",
    "                \"--output-sr\", str(output_sr.value),\n",
    "                \"--whisper-model\", whisper_model.value,\n",
    "                \"--min-duration\", str(min_duration.value),\n",
    "                \"--merge-gap\", str(merge_gap.value),\n",
    "                \"--verification-threshold\", str(verification_threshold.value),\n",
    "                \"--concat-silence\", str(concat_silence.value),\n",
    "                \"--diar-model\", diar_model.value,\n",
    "                \"--osd-model\", osd_model.value\n",
    "            ]\n",
    "            \n",
    "            if language.value.strip():\n",
    "                cmd_list.extend([\"--language\", language.value.strip()])\n",
    "            \n",
    "            if skip_demucs.value: cmd_list.append(\"--skip-demucs\")\n",
    "            if disable_speechbrain.value: cmd_list.append(\"--disable-speechbrain\")\n",
    "            if skip_rejected_transcripts.value: cmd_list.append(\"--skip-rejected-transcripts\")\n",
    "            if dry_run.value: cmd_list.append(\"--dry-run\")\n",
    "            if debug_log.value: cmd_list.append(\"--debug\")\n",
    "            if keep_temp_files.value: cmd_list.append(\"--keep-temp-files\")\n",
    "            \n",
    "            status_message.value = \"<div style='margin-top:15px; text-align:center; padding:10px; background:#fff3cd; color:#856404; border:1px solid #ffeeba; border-radius:5px;'>Status: Running Voice Extractor script...</div>\"\n",
    "            cmd_str = \" \".join(cmd_list)\n",
    "            print(f\"Executing command: {cmd_str}\\n--- LOG START ---\")\n",
    "            \n",
    "            process = subprocess.Popen(cmd_str, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, \n",
    "                                     text=True, bufsize=1, universal_newlines=True, shell=True)\n",
    "            for line in process.stdout:\n",
    "                print(line, end='')\n",
    "            exit_code = process.wait()\n",
    "            \n",
    "            if exit_code == 0:\n",
    "                status_message.value = \"<div style='margin-top:15px; text-align:center; padding:10px; background:#d4edda; color:#155724; border:1px solid #c3e6cb; border-radius:5px;'>Status: Voice extraction completed successfully!</div>\"\n",
    "                \n",
    "                run_output_dir_name = f\"{target_name.value.replace(' ', '_')}_{input_audio_file.stem}_SOLO_Split\"\n",
    "                actual_run_output_dir = Path(output_dir.value) / run_output_dir_name\n",
    "                \n",
    "                import datetime\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                base_name_for_zip = actual_run_output_dir.parent / f\"{target_name.value.replace(' ', '_')}_dataset_{timestamp}\"\n",
    "                zip_file_path = f\"{base_name_for_zip}.zip\"\n",
    "                \n",
    "                print(f\"\\nCreating ZIP archive of results: {zip_file_path}\")\n",
    "                shutil.make_archive(str(base_name_for_zip), 'zip', root_dir=actual_run_output_dir.parent, base_dir=actual_run_output_dir.name)\n",
    "                print(f\"‚úÖ ZIP created successfully: {zip_file_path}\")\n",
    "                \n",
    "                if \"Download to Computer\" in output_method.value:\n",
    "                    print(\"\\nPreparing to download ZIP file...\")\n",
    "                    colab_files.download(zip_file_path)\n",
    "                    print(\"‚úÖ Download initiated. Check your browser downloads.\")\n",
    "                \n",
    "                if push_to_hf.value:\n",
    "                    print(f\"\\nPreparing to push dataset to Hugging Face: {hf_dataset_repo.value}\")\n",
    "                    \n",
    "                    import tempfile\n",
    "                    temp_dir = tempfile.mkdtemp()\n",
    "                    print(f\"Created temporary directory: {temp_dir}\")\n",
    "                    \n",
    "                    verified_csv_path_list = list(actual_run_output_dir.glob(\"transcripts_solo_verified/*.csv\"))\n",
    "                    if not verified_csv_path_list:\n",
    "                         raise FileNotFoundError(f\"No verified transcript CSV found in {actual_run_output_dir / 'transcripts_solo_verified'}\")\n",
    "                    verified_csv_path = verified_csv_path_list[0]\n",
    "                    local_csv_path = os.path.join(temp_dir, os.path.basename(verified_csv_path))\n",
    "                    shutil.copy(verified_csv_path, local_csv_path)\n",
    "                    print(f\"Copied CSV to: {local_csv_path}\")\n",
    "                    \n",
    "                    local_audio_dir = os.path.join(temp_dir, \"audio\")\n",
    "                    os.makedirs(local_audio_dir, exist_ok=True)\n",
    "                    \n",
    "                    df_to_modify_for_hf = pd.read_csv(verified_csv_path) \n",
    "                    \n",
    "                    verified_segments_dir = actual_run_output_dir / \"target_segments_solo\" / f\"{target_name.value.replace(' ', '_')}_solo_verified\"\n",
    "                    if not verified_segments_dir.exists():\n",
    "                        print(f\"Warning: Could not find expected segments directory: {verified_segments_dir}\")\n",
    "                        for root, dirs, files_in_walk in os.walk(actual_run_output_dir):\n",
    "                            if files_in_walk and any(f.endswith(('.wav', '.mp3', '.flac')) for f in files_in_walk):\n",
    "                                verified_segments_dir = Path(root)\n",
    "                                print(f\"Found audio directory at: {verified_segments_dir}\")\n",
    "                                break\n",
    "                    \n",
    "                    copied_count = 0\n",
    "                    for idx, row in df_to_modify_for_hf.iterrows():\n",
    "                        filename = os.path.basename(row['filename'])\n",
    "                        src_path = verified_segments_dir / filename\n",
    "                        if not src_path.exists():\n",
    "                            print(f\"Warning: Could not find {src_path}, trying direct path from actual_run_output_dir / row['filename']\")\n",
    "                            src_path = actual_run_output_dir / row['filename'] \n",
    "                        \n",
    "                        if src_path.exists():\n",
    "                            dst_path = os.path.join(local_audio_dir, filename)\n",
    "                            shutil.copy(str(src_path), dst_path)\n",
    "                            df_to_modify_for_hf.at[idx, 'filename'] = os.path.join('audio', filename)\n",
    "                            copied_count += 1\n",
    "                        else:\n",
    "                            print(f\"Error: Could not find audio file for row: {row['filename']} at {src_path} or fallback.\")\n",
    "                    \n",
    "                    df_to_modify_for_hf.to_csv(local_csv_path, index=False)\n",
    "                    print(f\"Copied {copied_count} audio files and updated CSV paths in {local_csv_path}\")\n",
    "\n",
    "                    # KEY CHANGE: Use Dataset.from_pandas instead of load_dataset\n",
    "                    from datasets import Dataset, Audio as HFAudio\n",
    "                    print(f\"Reading updated CSV for HF from: {local_csv_path}\")\n",
    "                    df_for_hf = pd.read_csv(local_csv_path)\n",
    "                    \n",
    "                    print(\"Making 'filename' paths absolute for Hugging Face dataset creation...\")\n",
    "                    df_for_hf['filename'] = df_for_hf['filename'].apply(\n",
    "                        lambda rel_path: os.path.join(temp_dir, rel_path)\n",
    "                    )\n",
    "                    \n",
    "                    print(\"Creating Hugging Face Dataset from pandas DataFrame...\")\n",
    "                    ds = Dataset.from_pandas(df_for_hf)\n",
    "                    \n",
    "                    print(\"Casting 'filename' column to Audio object...\")\n",
    "                    ds = ds.cast_column('filename', HFAudio())\n",
    "                    \n",
    "                    print(f\"Pushing dataset to Hugging Face Hub: {hf_dataset_repo.value}\")\n",
    "                    ds.push_to_hub(\n",
    "                        hf_dataset_repo.value,\n",
    "                        private=hf_dataset_private.value,\n",
    "                        token=hf_token.value,\n",
    "                        embed_external_files=True\n",
    "                    )\n",
    "                    print(f\"‚úÖ Dataset pushed successfully to https://huggingface.co/datasets/{hf_dataset_repo.value}\")\n",
    "                    \n",
    "                    shutil.rmtree(temp_dir)\n",
    "                    print(\"Cleaned up temporary directory\")\n",
    "                    \n",
    "                with results_output:\n",
    "                    print(\"## Extraction Results Summary\\n\")\n",
    "                    try:\n",
    "                        concat_files_list = list(actual_run_output_dir.glob(\"concatenated_audio_solo/*.wav\"))\n",
    "                        if concat_files_list:\n",
    "                            concat_file = concat_files_list[0]\n",
    "                            print(f\"### Concatenated audio: {concat_file.name}\\n\")\n",
    "                            display(Audio(str(concat_file)))\n",
    "                        else:\n",
    "                            print(\"### No concatenated audio file found\\n\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"### Error displaying audio: {str(e)}\\n\")\n",
    "                    try:\n",
    "                        transcript_csv_files_list = list(actual_run_output_dir.glob(\"transcripts_solo_verified/*.csv\"))\n",
    "                        if transcript_csv_files_list:\n",
    "                            transcript_csv_for_display = transcript_csv_files_list[0]\n",
    "                            df_display = pd.read_csv(transcript_csv_for_display)\n",
    "                            print(f\"\\n### Transcript sample (from {transcript_csv_for_display.name}):\\n\")\n",
    "                            display(df_display.head())\n",
    "                            print(f\"\\nTotal segments: {len(df_display)}\")\n",
    "                        else:\n",
    "                            print(\"\\n### No transcript CSV found for display\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\n### Error displaying transcript: {str(e)}\")\n",
    "            else:\n",
    "                if \"Demucs failed! (RC: -9)\" in str(process.stdout):\n",
    "                    status_message.value = f\"\"\"<div style='margin-top:15px; text-align:center; padding:10px; background:#f8d7da; color:#721c24; border:1px solid #f5c6cb; border-radius:5px;'>\n",
    "                    Error: Demucs ran out of memory. Please check \"Skip Demucs\" option and try again.</div>\"\"\"\n",
    "                    print(\"\\n‚ùå ERROR: Demucs ran out of memory (RC: -9). This is common in Colab with large files.\")\n",
    "                    print(\"SOLUTION: Check the 'Skip Demucs Vocal Separation' option and try again.\")\n",
    "                else:\n",
    "                    status_message.value = f\"<div style='margin-top:15px; text-align:center; padding:10px; background:#f8d7da; color:#721c24; border:1px solid #f5c6cb; border-radius:5px;'>Error: Voice extraction failed with exit code {exit_code}.</div>\"\n",
    "                    print(f\"\\n‚ùå Process failed with exit code: {exit_code}\")\n",
    "        except Exception as e:\n",
    "            status_message.value = f\"<div style='margin-top:15px; text-align:center; padding:10px; background:#f8d7da; color:#721c24; border:1px solid #f5c6cb; border-radius:5px;'>Error: {str(e)}</div>\"\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "    \n",
    "    start_btn.disabled = False\n",
    "    start_btn.description = \"üöÄ Start Extraction\"\n",
    "    start_btn.icon = \"play\"\n",
    "    validate_inputs()\n",
    "\n",
    "start_btn.on_click(run_extraction)\n",
    "\n",
    "segment_params = widgets.VBox([min_duration, merge_gap, verification_threshold, concat_silence, \n",
    "                             disable_speechbrain, skip_rejected_transcripts])\n",
    "model_params = widgets.VBox([diar_model, osd_model])\n",
    "debug_params = widgets.VBox([dry_run, debug_log, keep_temp_files])\n",
    "\n",
    "advanced_accordion = widgets.Accordion(\n",
    "    children=[segment_params, model_params, debug_params],\n",
    "    titles=('Segment Parameters', 'Model Options', 'Debug & Temp Files')\n",
    ")\n",
    "\n",
    "main_layout = widgets.VBox([\n",
    "    widgets.HTML(\"<h1 style='text-align:center; color:#1A73E8;'>Voice Extractor - Google Colab Interface</h1>\"),\n",
    "    widgets.HTML(\"<p style='text-align:center;'>Extract solo voice segments of a target speaker from multi-speaker recordings</p>\"),\n",
    "    auth_section,\n",
    "    hf_token,\n",
    "    input_section,\n",
    "    audio_dir,\n",
    "    reference_file,\n",
    "    target_name,\n",
    "    output_dir,\n",
    "    processing_section,\n",
    "    output_sr,\n",
    "    whisper_model,\n",
    "    language,\n",
    "    performance_section,\n",
    "    memory_warning,\n",
    "    widgets.HBox([skip_demucs, skip_demucs_description]),\n",
    "    advanced_section,\n",
    "    advanced_accordion,\n",
    "    output_section,\n",
    "    output_method,\n",
    "    push_to_hf,\n",
    "    hf_dataset_repo,\n",
    "    hf_dataset_private,\n",
    "    widgets.HBox([start_btn, validation_message]),\n",
    "    status_message,\n",
    "    create_section(\"Processing Log\"),\n",
    "    log_output,\n",
    "    create_section(\"Results\"),\n",
    "    results_output\n",
    "])\n",
    "\n",
    "validate_inputs()\n",
    "display(main_layout)\n",
    "print(\"Voice Extractor Colab UI ready. IMPORTANT: If you've just run the setup cell for the first time or changed library versions, please RESTART THE RUNTIME now (Runtime -> Restart runtime) before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8137fb8",
   "metadata": {},
   "source": [
    "# Voice Extractor - Usage Instructions\n",
    "\n",
    "This notebook provides a graphical interface for the [Voice Extractor](https://github.com/ReisCook/Voice_Extractor) tool, which identifies, isolates, and transcribes clean solo segments of a target speaker from multi-speaker audio recordings.\n",
    "\n",
    "## How to Use\n",
    "\n",
    "1. **Authentication**: Enter your HuggingFace User Access Token. This is required to access PyAnnote models.\n",
    "2. **Input Files**:\n",
    "   - Specify the folder containing your audio (first compatible audio file will be processed)\n",
    "   - Select a clean reference audio of ONLY your target speaker (5-30 seconds)\n",
    "   - Enter a name for your target speaker\n",
    "   - Choose an output directory for results\n",
    "3. **Processing Options**: Configure sample rate, transcription model, and other settings\n",
    "4. **Advanced Options**: Fine-tune segment parameters, model selection, and debug settings\n",
    "5. **Output Handling**: Choose how to save results and optionally push to Hugging Face\n",
    "6. **Start Processing**: Click the \"Start Extraction\" button when all required fields are filled\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- You need to accept the terms of use for the following PyAnnote models on Hugging Face (need to add the other gated model links):\n",
    "  - [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)\n",
    "  - [pyannote/overlapped-speech-detection](https://huggingface.co/pyannote/overlapped-speech-detection)\n",
    "  - [pyannote/segmentation-3.0](https://huggingface.co/pyannote/segmentation-3.0)\n",
    "- For optimal results, provide a clean reference audio with only the target speaker's voice\n",
    "- The \"Dry Run\" option is helpful for testing as it processes only the first 60 seconds\n",
    "- GPU acceleration is automatically used when available\n",
    "\n",
    "For more detailed documentation, visit the [Voice Extractor GitHub repository](https://github.com/ReisCook/Voice_Extractor).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
